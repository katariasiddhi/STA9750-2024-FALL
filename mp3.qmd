---
title: "Electoral College Project - MiniProject #03"
author: "Siddhi Kataria"
date: "2024-11-13"
output:
  html_document:
    toc: true
---

## Introduction

The United States' Electoral College system is frequently debated for its fairness in representing voters' preferences. This project explores alternative Electoral College allocation methods---proportional and district-based allocation---against the traditional winner-take-all approach. By analyzing election data, the goal is to evaluate whether these alternative methods could yield more representative outcomes and potentially reduce discrepancies between the popular vote and election results.

## Set-Up and Initial Exploration

### **Data I: US House Election Votes from 1976 to 2022**

```{r}
# Load necessary libraries
library(dplyr)

# Load the House election data
house_data <- read.csv("/Users/siddhikataria/Downloads/1976-2022-house.csv")

# Load the Presidential vote data
presidential_data <- read.csv("/Users/siddhikataria/Downloads/1976-2020-president.csv")

# Inspect both data structures
str(house_data)
head(house_data)
str(presidential_data)
head(presidential_data)
```

### **Data II: Congressional Boundary Files 1976 to 2012**

```{r}

# List of URLs for the shapefiles
urls <- c(
  "https://cdmaps.polisci.ucla.edu/shp/districts001.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts002.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts003.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts004.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts005.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts006.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts007.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts008.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts009.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts010.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts011.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts012.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts013.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts014.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts015.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts016.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts017.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts018.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts019.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts020.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts021.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts022.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts023.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts024.zip",
  "https://cdmaps.polisci.ucla.edu/shp/districts025.zip"
)

# Directory to save the downloaded files
save_directory <- "congressional_shapefiles"

# Create directory if it does not exist
if (!dir.exists(save_directory)) {
  dir.create(save_directory)
}

# Loop through each URL and download the file if not already present
for (url in urls) {
  # Extract the file name from the URL
  file_name <- basename(url)
  file_path <- file.path(save_directory, file_name)
  
  # Check if the file already exists to avoid re-downloading
  if (!file.exists(file_path)) {
    cat("Downloading", file_name, "...\n")
    # Download file
    download.file(url, file_path, mode = "wb")
    cat(file_name, "downloaded successfully.\n")
  } else {
    cat(file_name, "already exists, skipping download.\n")
  }
}

```

### **Data III: Congressional Boundary Files 2014 to Present**

```{r}

# Define base URLs for each year
base_urls <- list(
  "2014" = "https://www2.census.gov/geo/tiger/TIGER2014/",
  "2015" = "https://www2.census.gov/geo/tiger/TIGER2015/",
  "2016" = "https://www2.census.gov/geo/tiger/TIGER2016/",
  "2017" = "https://www2.census.gov/geo/tiger/TIGER2017/",
  "2018" = "https://www2.census.gov/geo/tiger/TIGER2018/",
  "2019" = "https://www2.census.gov/geo/tiger/TIGER2019/",
  "2020" = "https://www2.census.gov/geo/tiger/TIGER2020/",
  "2021" = "https://www2.census.gov/geo/tiger/TIGER2021/",
  "2022" = "https://www2.census.gov/geo/tiger/TIGER2022/"
)

# Congressional district codes per year
congress_sessions <- list(
  "2014" = "113", "2015" = "114", "2016" = "114", "2017" = "115",
  "2018" = "115", "2019" = "116", "2020" = "116", "2021" = "117",
  "2022" = "117"
)

# Directory to save the downloaded files
save_directory <- "census_shapefiles"

# Create the directory if it does not exist
if (!dir.exists(save_directory)) {
  dir.create(save_directory)
}

# Loop through each year to construct URLs and download files
for (year in names(base_urls)) {
  # Construct URL and file names
  base_url <- base_urls[[year]]
  congress_session <- congress_sessions[[year]]
  file_name <- paste0("congressional_district_", year, ".zip")
  file_path <- file.path(save_directory, file_name)
  
  # Formulate the full URL for the congressional shapefile
  url <- paste0(base_url, "CD/tl_", year, "_us_cd", congress_session, ".zip")
  
  # Check if file already exists to avoid re-downloading
  if (!file.exists(file_path)) {
    cat("Downloading", file_name, "for year", year, "...\n")
    # Download the file
    tryCatch({
      download.file(url, file_path, mode = "wb")
      cat(file_name, "downloaded successfully.\n")
    }, error = function(e) {
      cat("Failed to download:", url, "\nSkipping this year.\n")
    })
  } else {
    cat(file_name, "already exists, skipping download.\n")
  }
}
```

#### **Initial Exploration of Vote Count Data**

1.  Which states have gained and lost the most seats in the US House of Representatives between 1976 and 2022?

```{r}
# Load the necessary libraries
library(dplyr)
library(tidyr)

# Read in the house data file with the full path
house_data <- read.csv("/Users/siddhikataria/Downloads/1976-2022-house.csv", header = TRUE)

# Check if the data loaded correctly by displaying the first few rows
head(house_data)

```

```{r}

# Load the house data file
house_data <- read.csv("/Users/siddhikataria/Downloads/1976-2022-house.csv", header = TRUE)

# Filter and summarize the seat counts for 1976 and 2022
seat_changes <- house_data %>%
  filter(year %in% c(1976, 2022)) %>%
  group_by(state, year) %>%
  summarise(seat_count = n_distinct(district), .groups = 'drop') %>%
  pivot_wider(names_from = year, values_from = seat_count, names_prefix = "year_") %>%
  mutate(seat_change = year_2022 - year_1976) %>%
  arrange(desc(seat_change))

# Display the result
print(seat_changes)



```

2\. Identifying Potential Fusion Voting Impact in New York \*\*\*

```{r}
# Filter the data for New York and 2021
ny_2021_data <- congress_data %>%
  filter(state == "New York", year == 2021)

# View the data
print(ny_2021_data)

```

3.  

```{r}
# Rename columns for consistency in case necessary (candidate and party should be consistent)
ny_2022_fusion_data <- ny_2022_fusion_data %>%
  rename(candidate_name = candidate)  # Renaming candidate for consistency

ny_major_party_votes <- ny_major_party_votes %>%
  rename(candidate_name = candidate)  # Renaming candidate for consistency

# Check if column names match
print(colnames(ny_2022_fusion_data))
print(colnames(ny_major_party_votes))

```

```{r}
# Merge datasets on the renamed 'candidate_name' and 'party' columns
ny_fusion_comparison <- ny_2022_fusion_data %>%
  group_by(candidate_name, party) %>%
  summarise(fusion_votes = sum(candidatevotes), .groups = 'drop') %>%
  left_join(ny_major_party_votes, by = c("candidate_name", "party")) %>%
  mutate(vote_difference = fusion_votes - major_party_votes)

# Display the comparison
print(ny_fusion_comparison)

```

```{}
```

```{}
```

### **Importing and Plotting Shape File Data**

```{r}
# Load necessary libraries
library(ggplot2)
library(sf)

# Download the shapefile if not already downloaded
if(!file.exists("nyc_borough_boundaries.zip")){
  download.file("https://data.cityofnewyork.us/api/geospatial/tqmj-j8zm?method=export&format=Shapefile", 
                destfile="nyc_borough_boundaries.zip")
}

# Unzip the shapefile and extract the contents
td <- tempdir()  # Temporary directory
zip_contents <- unzip("nyc_borough_boundaries.zip", exdir = td)

# Find the .shp file in the extracted contents
fname_shp <- zip_contents[grepl("shp$", zip_contents)]

# Read the shapefile into an sf object
nyc_sf <- read_sf(fname_shp)

# Print the structure of the data
print(nyc_sf)

# Plot the shapefile using ggplot2
ggplot(data = nyc_sf) +
  geom_sf() +  # geom_sf() is used to plot spatial data
  theme_minimal() +  # Minimal theme for the plot
  labs(title = "New York City Borough Boundaries", 
       subtitle = "Shape File Data",
       caption = "Source: NYC Open Data")  # Customize the plot title and labels

```

Task 4: Automate Zip File Extraction

```{r}
# Check the structure of the data
str(nyc_sf)




```

```{r}


```
